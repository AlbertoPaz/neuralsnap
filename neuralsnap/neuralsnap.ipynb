{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NeuralSnap\n",
    "\n",
    "Works by generating a caption for the image using a model I trained on the MS COCO data set, with recurrent and convolutional neural networks using NeuralTalk2. That (brief) caption is then expanded into a poem using a recurrent neural network (Karpathy's Char-RNN), which I trained on a ~40 MB corpus of poetry.\n",
    "\n",
    "By Ross Goodwin, 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import json\n",
    "import re\n",
    "from string import Template\n",
    "from upload_to_s3 import upload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_title = \"Epoch 64.24, Loss 1.1434, Dropout 0.25, 512/16[6,7,8,9], 180-degree test\"\n",
    "ntalk_model_fp = \"/home/ubuntu/models/model_id_mscoco_01_ft_07.t7_cpu.t7\"\n",
    "rnn_model_fp = \"/home/ubuntu/models/lm_poetry5_d025_long2_epoch64.24_1.1434.t7_cpu.t7\"\n",
    "image_folder_fp = \"/home/ubuntu/test_images/180\"\n",
    "num_images = '1'\n",
    "stanza_len = '512'\n",
    "highlight_color = '#D64541' # Valencia Red\n",
    "num_steps = 16\n",
    "tgt_steps = [6,7,8,9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static Global Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SCRIPT_PATH = '/home/ubuntu/neuralsnap'\n",
    "NEURALTALK2_PATH = '/home/ubuntu/neuraltalk2'\n",
    "CHARRNN_PATH = '/home/ubuntu/char-rnn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NeuralTalk2 Image Captioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir(NEURALTALK2_PATH)\n",
    "\n",
    "ntalk_cmd_list = [\n",
    "    'th',\n",
    "    'eval.lua',\n",
    "    '-model',\n",
    "    ntalk_model_fp,\n",
    "    '-image_folder',\n",
    "    image_folder_fp,\n",
    "    '-num_images',\n",
    "    num_images,\n",
    "    '-gpuid',\n",
    "    '-1'\n",
    "]\n",
    "\n",
    "ntalk_proc = subprocess.Popen(ntalk_cmd_list)\n",
    "ntalk_proc.communicate()\n",
    "\n",
    "with open(NEURALTALK2_PATH+'/vis/vis.json') as caption_json:\n",
    "    caption_obj_list = json.load(caption_json)\n",
    "    \n",
    "caption_obj_list *= num_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## RNN Caption Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir(CHARRNN_PATH)\n",
    "\n",
    "expansion_obj_list = list()\n",
    "caption_list = list()\n",
    "\n",
    "for i in tgt_steps:\n",
    "    obj = caption_obj_list[i]\n",
    "    caption = obj['caption']\n",
    "    prepped_caption = caption[0].upper() + caption[1:]\n",
    "    \n",
    "    rnn_cmd_list = [\n",
    "        'th',\n",
    "        'sample.lua',\n",
    "        rnn_model_fp,\n",
    "        '-length',\n",
    "        stanza_len,\n",
    "        '-verbose',\n",
    "        '0',\n",
    "        '-temperature',\n",
    "        str((i+1.0)/float(num_steps)),\n",
    "        '-primetext',\n",
    "        prepped_caption,\n",
    "        '-gpuid',\n",
    "        '-1'\n",
    "    ]\n",
    "\n",
    "    rnn_proc = subprocess.Popen(\n",
    "        rnn_cmd_list,\n",
    "        stdout=subprocess.PIPE\n",
    "    )\n",
    "    expansion = rnn_proc.stdout.read()\n",
    "    \n",
    "    expansion_obj_list.append({\n",
    "        'id': obj['image_id'],\n",
    "        'text': expansion\n",
    "    })\n",
    "    \n",
    "    caption_list.append((prepped_caption, '<span style=\"color:'+highlight_color+';\">'+prepped_caption+'</span>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post Processing and Upload to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_fps = map(\n",
    "    lambda x: os.path.join(NEURALTALK2_PATH, 'vis', 'imgs', 'img%s.jpg'%x['id']),\n",
    "    expansion_obj_list\n",
    ")\n",
    "\n",
    "img_url = upload(img_fps.pop())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fix_end_punctuation(exp):\n",
    "    try:\n",
    "        first_sentence, remainder = exp.rsplit('.', 1)\n",
    "        first_sentence = first_sentence.strip()\n",
    "        if remainder[0] in [\"\\'\", '\\\"', '”', '’']:\n",
    "            first_sentence += '.' + remainder[0]\n",
    "        else:\n",
    "            first_sentence += '.'\n",
    "        return first_sentence\n",
    "    except:\n",
    "        return exp.rsplit(' ', 1)[0] + '...'\n",
    "\n",
    "expansions = map(\n",
    "    lambda x: fix_end_punctuation(x['text']),\n",
    "    expansion_obj_list\n",
    ")\n",
    "\n",
    "exps_tups = zip(expansions, caption_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_span(exp, tup):\n",
    "    original, modified = map(lambda x: x.decode('utf8').encode('ascii', 'xmlcharrefreplace'), tup)\n",
    "    return exp.replace(original, modified)\n",
    "    \n",
    "final_exps = map(lambda (x,y): add_span(x,y), exps_tups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_html_block(exp):\n",
    "    exp_ascii = exp.decode('utf8').encode('ascii', 'xmlcharrefreplace')\n",
    "    exp_ascii = exp_ascii.replace('\\n', '</p><p>')\n",
    "    return '<p>%s</p>' % exp_ascii\n",
    "\n",
    "img_block = '<p class=\"text-center\"><a href=\"%s\"><img src=\"%s\" width=\"275px\" class=\"img-thumbnail\"></a></p>' % (img_url, img_url)\n",
    "body_html = img_block + '\\n'.join(map(make_html_block, final_exps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://s3.amazonaws.com/rossgoodwin/neuralsnap/145257681567_Epoch_64_24_Loss_1_1434_Dropout_0_25_512_16_6_7_8_9_180_degree_test.html\n"
     ]
    }
   ],
   "source": [
    "with open(SCRIPT_PATH+'/template.html', 'r') as tempfile:\n",
    "    html_temp_str = tempfile.read()\n",
    "    \n",
    "html_temp = Template(html_temp_str)\n",
    "html_result = html_temp.substitute(title=output_title, body=body_html)\n",
    "html_fp = '%s/pages/%s.html' % (SCRIPT_PATH, re.sub(r'\\W+', '_', output_title))\n",
    "\n",
    "with open(html_fp, 'w') as outfile:\n",
    "    outfile.write(html_result)\n",
    "    \n",
    "print upload(html_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126.523452997\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "print end_time - start_time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
