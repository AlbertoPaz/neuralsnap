{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NeuralSnap\n",
    "\n",
    "Works by generating a caption for the image using a model I trained on the MS COCO data set, with recurrent and convolutional neural networks using NeuralTalk2. That (brief) caption is then expanded into a poem using a recurrent neural network (Karpathy's Char-RNN), which I trained on a ~40 MB corpus of poetry.\n",
    "\n",
    "By Ross Goodwin, 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import json\n",
    "import re\n",
    "from string import Template\n",
    "from upload_to_s3 import upload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Parameters\n",
    "\n",
    "Replace these values with parameters that match your installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_title = \"Your Title Here\"\n",
    "ntalk_model_fp = \"/home/rg/projects/neuralsnap/models/2016-01-12_neuraltalk2_model_01_rg.t7\"\n",
    "rnn_model_fp = \"/home/rg/projects/neuralsnap/models/2016-01-12_char-rnn_model_02_rg.t7\"\n",
    "image_folder_fp = \"/home/rg/projects/neuralsnap/testimg/01\"\n",
    "num_images = '1'\n",
    "stanza_len = '512'\n",
    "highlight_color = '#D64541' # Valencia Red\n",
    "num_steps = 16\n",
    "tgt_steps = [6,7,8,9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static Global Parameters\n",
    "\n",
    "Replace these too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SCRIPT_PATH = os.getcwd()\n",
    "NEURALTALK2_PATH = '/home/rg/projects/neuralsnap/neuraltalk2'\n",
    "CHARRNN_PATH = '/home/rg/projects/neuralsnap/char-rnn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NeuralTalk2 Image Captioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(NEURALTALK2_PATH)\n",
    "\n",
    "ntalk_cmd_list = [\n",
    "    'th',\n",
    "    'eval.lua',\n",
    "    '-model',\n",
    "    ntalk_model_fp,\n",
    "    '-image_folder',\n",
    "    image_folder_fp,\n",
    "    '-num_images',\n",
    "    num_images,\n",
    "    '-gpuid',\n",
    "    '-1'\n",
    "]\n",
    "\n",
    "ntalk_proc = subprocess.Popen(ntalk_cmd_list)\n",
    "ntalk_proc.communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(NEURALTALK2_PATH+'/vis/vis.json') as caption_json:\n",
    "    caption_obj_list = json.load(caption_json)\n",
    "    \n",
    "caption_obj_list *= num_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## RNN Caption Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPANDING AT TEMPERATURE 0.4375\n",
      "EXPANDING AT TEMPERATURE 0.5\n",
      "EXPANDING AT TEMPERATURE 0.5625\n",
      "EXPANDING AT TEMPERATURE 0.625\n"
     ]
    }
   ],
   "source": [
    "os.chdir(CHARRNN_PATH)\n",
    "\n",
    "expansion_obj_list = list()\n",
    "caption_list = list()\n",
    "\n",
    "for i in tgt_steps:\n",
    "    obj = caption_obj_list[i]\n",
    "    caption = obj['caption']\n",
    "    prepped_caption = caption[0].upper() + caption[1:]\n",
    "    \n",
    "    temp = str((i+1.0)/float(num_steps))\n",
    "    print \"EXPANDING AT TEMPERATURE \" + temp\n",
    "    \n",
    "    rnn_cmd_list = [\n",
    "        'th',\n",
    "        'sample.lua',\n",
    "        rnn_model_fp,\n",
    "        '-length',\n",
    "        stanza_len,\n",
    "        '-verbose',\n",
    "        '0',\n",
    "        '-temperature',\n",
    "        temp,\n",
    "        '-primetext',\n",
    "        prepped_caption,\n",
    "        '-gpuid',\n",
    "        '-1'\n",
    "    ]\n",
    "\n",
    "    rnn_proc = subprocess.Popen(\n",
    "        rnn_cmd_list,\n",
    "        stdout=subprocess.PIPE\n",
    "    )\n",
    "    expansion = rnn_proc.stdout.read()\n",
    "    \n",
    "    expansion_obj_list.append({\n",
    "        'id': obj['image_id'],\n",
    "        'text': expansion\n",
    "    })\n",
    "    \n",
    "    caption_list.append((prepped_caption, '<span style=\"color:'+highlight_color+';\">'+prepped_caption+'</span>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post Processing and Upload to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_fps = map(\n",
    "    lambda x: os.path.join(NEURALTALK2_PATH, 'vis', 'imgs', 'img%s.jpg'%x['id']),\n",
    "    expansion_obj_list\n",
    ")\n",
    "\n",
    "img_url = img_fps.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fix_end_punctuation(exp):\n",
    "    try:\n",
    "        first_sentence, remainder = exp.rsplit('.', 1)\n",
    "        first_sentence = first_sentence.strip()\n",
    "        if remainder[0] in [\"\\'\", '\\\"', '”', '’']:\n",
    "            first_sentence += '.' + remainder[0]\n",
    "        else:\n",
    "            first_sentence += '.'\n",
    "        return first_sentence\n",
    "    except:\n",
    "        return exp.rsplit(' ', 1)[0] + '...'\n",
    "\n",
    "expansions = map(\n",
    "    lambda x: fix_end_punctuation(x['text']),\n",
    "    expansion_obj_list\n",
    ")\n",
    "\n",
    "exps_tups = zip(expansions, caption_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_span(exp, tup):\n",
    "    original, modified = map(lambda x: x.decode('utf8').encode('ascii', 'xmlcharrefreplace'), tup)\n",
    "    return exp.replace(original, modified)\n",
    "    \n",
    "final_exps = map(lambda (x,y): add_span(x,y), exps_tups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_html_block(exp):\n",
    "    exp_ascii = exp.decode('utf8').encode('ascii', 'xmlcharrefreplace')\n",
    "    exp_ascii = exp_ascii.replace('\\n', '</p><p>')\n",
    "    return '<p>%s</p>' % exp_ascii\n",
    "\n",
    "img_block = '<p class=\"text-center\"><a href=\"%s\"><img src=\"%s\" width=\"275px\" class=\"img-thumbnail\"></a></p>' % (img_url, img_url)\n",
    "body_html = img_block + '\\n'.join(map(make_html_block, final_exps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(SCRIPT_PATH+'/template.html', 'r') as tempfile:\n",
    "    html_temp_str = tempfile.read()\n",
    "    \n",
    "html_temp = Template(html_temp_str)\n",
    "html_result = html_temp.substitute(title=output_title, body=body_html)\n",
    "html_fp = '%s/pages/%s.html' % (SCRIPT_PATH, re.sub(r'\\W+', '_', output_title))\n",
    "\n",
    "with open(html_fp, 'w') as outfile:\n",
    "    outfile.write(html_result)\n",
    "    \n",
    "# print upload(html_fp)\n",
    "\n",
    "# Sorry, you'll have to build your own upload\n",
    "# function if you want to share your results\n",
    "# on the web... for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "980.295531034\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "print end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import webbrowser\n",
    "\n",
    "webbrowser.open_new_tab('file://'+html_fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
